const OpenAI = require('openai');
const RAGService = require('../RAG_Core/RAG_Core.service');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const ClientService = require('../Client/Client.service');
const Client = require('../../models/Client'); // Direct model access for updates if needed, or use service

class AIAgentService {
    async generateResponse(clientNumber, textInput) {
        try {
            console.log(`Processing message for ${clientNumber}: ${textInput}`);

            // Get Client State
            const client = await ClientService.findOrCreateClient(clientNumber);
            let currentState = client.conversation_stage || 'START';
            const input = textInput.trim();

            const MENU_TEXT = `Bem-vindo ao *MOHSIS Sistema de Intelig√™ncia do Agroneg√≥cio* üåæ\n\nSou seu assistente jur√≠dico rural. Escolha uma op√ß√£o abaixo para come√ßarmos:\n\n` +
                `1Ô∏è‚É£ *An√°lise de Risco Clim√°tico/Safra*\n(Avaliar perdas e frustra√ß√£o de safra)\n\n` +
                `2Ô∏è‚É£ *An√°lise de D√≠vidas*\n(Simular capacidade de pagamento)\n\n` +
                `3Ô∏è‚É£ *Assistente Jur√≠dico*\n(Tirar d√∫vidas sobre legisla√ß√£o)\n\n` +
                `9Ô∏è‚É£ *Outras D√∫vidas*\n(Chat livre com IA)\n\n` +
                `_Digite apenas o n√∫mero da op√ß√£o desejada._`;

            // --- RESET TRIGGER ---
            // If user says "Menu", "Inicio", "Oi" (and isn't in middle of form) -> Reset to Menu
            if (['oi', 'ol√°', 'ola', 'menu', 'inicio', 'in√≠cio', 'reset', 'come√ßar'].includes(input.toLowerCase())) {
                currentState = 'START';
                await client.update({ conversation_stage: 'START' });
            }

            // --- STATE: START / MENU ---
            if (currentState === 'START' && !['1', '2', '3', '9'].includes(input)) {
                // If checking for START, we almost ALWAYS show menu, unless input is a direct option
                console.log(`State is START. Showing Text Menu.`);
                await client.update({ conversation_stage: 'MENU_SHOWN' });
                return MENU_TEXT;
            }

            // --- OPTION SELECTION ---
            if (currentState === 'MENU_SHOWN' || ['1', '2', '3', '9'].includes(input)) {

                if (input === '1') {
                    await client.update({ conversation_stage: 'WAITING_CLIMATE_DATA' });
                    return "üåæ *An√°lise de Risco Clim√°tico*\n\nPara prosseguir, por favor me envie:\n1. O nome da sua cidade/munic√≠pio.\n2. Se houve seca, geada ou excesso de chuva.\n\n_Voc√™ tamb√©m pode enviar uma foto do laudo ou √°udio explicando._";
                }

                if (input === '2') {
                    await client.update({ conversation_stage: 'WAITING_FINANCE_DATA' });
                    return "üí∞ *An√°lise Financeira*\n\nVamos simular sua d√≠vida. Por favor, me diga:\nQual o valor do financiamento e o prazo em meses?\n\n_Ex: 200.000 em 60 meses_";
                }

                if (input === '3') {
                    await client.update({ conversation_stage: 'JURIDICAL_CHAT' });
                    return "‚öñÔ∏è *Assistente Jur√≠dico*\n\nEstou aqui para ajudar com d√∫vidas legais do MCR. Qual sua d√∫vida espec√≠fica sobre legisla√ß√£o rural?";
                }

                if (input === '9') {
                    await client.update({ conversation_stage: 'FREE_CHAT' });
                    return "üí¨ *Chat Livre*\n\nPode perguntar o que quiser sobre cr√©dito rural.";
                }

                // If user typed random text while in Menu, assuming they want RAG or confused
                // We fallback to checking if it's broad text or show menu again
                if (currentState === 'MENU_SHOWN') {
                    // Invalid option in menu state -> Show Menu again nicely
                    await client.update({ conversation_stage: 'START' }); // Reset
                    return "Op√ß√£o n√£o reconhecida. Por favor, escolha uma op√ß√£o do menu ou digite 'Menu' para ver as op√ß√µes.";
                }
            }

            // --- RAG FLOW (For Juridical/Free Chat or Fallback) ---
            // Proceed to RAG...

            // --- RAG FLOW (Existing Logic) ---

            // 1. Generate Embedding
            const embedding = await RAGService.generateEmbedding(textInput);

            // 2. Search Chunks (RAG)
            const chunks = await RAGService.searchChunks(embedding);

            // If no relevant chunks found (basic threshold check via empty array if service implements it, or fallback)
            // For now assuming service always returns arrays.

            // Format chunks for context
            const contextText = chunks.map(c =>
                `[Source: ${c.source}, DocID: ${c.doc_id}, ChunkID: ${c.chunk_id}]: ${c.text}`
            ).join('\n\n');

            // 3. Construct Prompt
            const systemPrompt = `
            Voc√™ √© um assistente jur√≠dico/financeiro especializado em Cr√©dito Rural (LegalFarm AI).
            Sua miss√£o √© responder com base ESTRITAMENTE no contexto fornecido abaixo.
            
            PROTOCOLO ANTI-ALUCINA√á√ÉO:
            - Se a resposta n√£o estiver no contexto, diga "N√£o encontrei essa informa√ß√£o na minha base de dados jur√≠dica."
            - N√ÉO invente leis ou dados.
            - CITE as fontes usando doc_id e chunk_id.
            
            FORMATO OBRIGAT√ìRIO DE RESPOSTA (JSON):
            {
                "resposta": "Texto da resposta ao usu√°rio...",
                "citacoes": [
                    { "doc_id": "...", "chunk_id": "..." }
                ],
                "score": 0.0 a 1.0 (confian√ßa)
            }
            
            CONTEXTO:
            ${contextText}
            `;

            // 4. Call LLM
            const completion = await openai.chat.completions.create({
                model: "gpt-4o-mini", // Using 'mini' as requested for cost/speed
                messages: [
                    { role: "system", content: systemPrompt },
                    { role: "user", content: textInput }
                ],
                response_format: { type: "json_object" },
                temperature: 0.1 // Low temp for factual accuracy
            });

            const responseContent = completion.choices[0].message.content;
            const parsedResponse = JSON.parse(responseContent);

            // 5. Validate Citations
            const validation = await RAGService.validateCitations(parsedResponse.citacoes);

            if (!validation.valid) {
                console.warn("Invalid citations detected, triggering fallback:", validation.missing);
                return "Pe√ßo desculpas, mas verifiquei minhas fontes e encontrei uma inconsist√™ncia na cita√ß√£o do documento. Poderia reformular a pergunta?";
            }

            return parsedResponse.resposta;

        } catch (error) {
            console.error("Error in AI Agent:", error);
            return "Desculpe, ocorreu um erro interno ao processar sua solicita√ß√£o.";
        }
    }
}

module.exports = new AIAgentService();
